apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: foodfund-microservices-alerts
  namespace: monitoring
  labels:
    release: prometheus
spec:
  groups:
  # HTTP Service Alerts
  - name: http-services
    interval: 30s
    rules:
    # High error rate alert
    - alert: HighHTTPErrorRate
      expr: |
        (
          sum(rate(foodfund_http_request_errors_total[5m])) by (service)
          /
          sum(rate(foodfund_http_requests_total[5m])) by (service)
        ) > 0.05
      for: 5m
      labels:
        severity: critical
        component: http
      annotations:
        summary: "High HTTP error rate on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has {{ $value | humanizePercentage }} error rate (threshold: 5%)"
        
    # High latency alert
    - alert: HighHTTPLatency
      expr: |
        histogram_quantile(0.95,
          rate(foodfund_http_request_duration_seconds_bucket[5m])
        ) > 1
      for: 5m
      labels:
        severity: warning
        component: http
      annotations:
        summary: "High HTTP latency on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has p95 latency of {{ $value }}s (threshold: 1s)"
  
  # Service Availability Alerts
  - name: service-availability
    interval: 30s
    rules:
    # Service down
    - alert: ServiceDown
      expr: up{job=~".*-service"} == 0
      for: 2m
      labels:
        severity: critical
        component: availability
      annotations:
        summary: "Service {{ $labels.job }} is down"
        description: "Service {{ $labels.job }} has been unreachable for more than 2 minutes"
    
    # Low request rate (possible issue)
    - alert: LowRequestRate
      expr: |
        rate(foodfund_http_requests_total[5m]) < 0.1
      for: 10m
      labels:
        severity: warning
        component: availability
      annotations:
        summary: "Low request rate on {{ $labels.service }}"
        description: "Service {{ $labels.service }} receiving < 0.1 req/s for 10 minutes"
  
  # Resource Usage Alerts
  - name: resource-usage
    interval: 30s
    rules:
    # High memory usage
    - alert: HighMemoryUsage
      expr: |
        (
          nodejs_heap_size_used_bytes
          /
          process_resident_memory_bytes
        ) > 0.8
      for: 10m
      labels:
        severity: warning
        component: resources
      annotations:
        summary: "High memory usage on {{ $labels.service }}"
        description: "Service {{ $labels.service }} using {{ $value | humanizePercentage }} of memory"
    
    # High CPU usage
    - alert: HighCPUUsage
      expr: |
        rate(process_cpu_seconds_total[5m]) > 0.8
      for: 10m
      labels:
        severity: warning
        component: resources
      annotations:
        summary: "High CPU usage on {{ $labels.service }}"
        description: "Service {{ $labels.service }} using {{ $value | humanizePercentage }} of CPU"
    
    # Event loop lag
    - alert: HighEventLoopLag
      expr: |
        nodejs_eventloop_lag_seconds > 0.1
      for: 5m
      labels:
        severity: warning
        component: performance
      annotations:
        summary: "High event loop lag on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has event loop lag of {{ $value }}s"
  
  # gRPC Alerts
  - name: grpc-services
    interval: 30s
    rules:
    # High gRPC error rate
    - alert: HighGRPCErrorRate
      expr: |
        (
          sum(rate(foodfund_grpc_request_errors_total[5m])) by (service)
          /
          sum(rate(foodfund_grpc_requests_total[5m])) by (service)
        ) > 0.05
      for: 5m
      labels:
        severity: critical
        component: grpc
      annotations:
        summary: "High gRPC error rate on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has {{ $value | humanizePercentage }} gRPC error rate"
    
    # High gRPC latency
    - alert: HighGRPCLatency
      expr: |
        histogram_quantile(0.95,
          rate(foodfund_grpc_request_duration_seconds_bucket[5m])
        ) > 0.5
      for: 5m
      labels:
        severity: warning
        component: grpc
      annotations:
        summary: "High gRPC latency on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has p95 gRPC latency of {{ $value }}s"
  
  # Database Alerts
  - name: database
    interval: 30s
    rules:
    # Slow database queries
    - alert: SlowDatabaseQueries
      expr: |
        histogram_quantile(0.95,
          rate(foodfund_db_query_duration_seconds_bucket[5m])
        ) > 0.5
      for: 5m
      labels:
        severity: warning
        component: database
      annotations:
        summary: "Slow database queries on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has p95 query time of {{ $value }}s"
    
    # High database connection usage
    - alert: HighDatabaseConnections
      expr: |
        foodfund_db_connections_active > 50
      for: 5m
      labels:
        severity: warning
        component: database
      annotations:
        summary: "High database connections on {{ $labels.service }}"
        description: "Service {{ $labels.service }} has {{ $value }} active connections"
  
  # Pod Alerts
  - name: pod-health
    interval: 30s
    rules:
    # Pod restarts
    - alert: PodRestartingTooOften
      expr: |
        rate(kube_pod_container_status_restarts_total{namespace="foodfund-k8s"}[15m]) > 0.1
      for: 5m
      labels:
        severity: warning
        component: kubernetes
      annotations:
        summary: "Pod {{ $labels.pod }} restarting frequently"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has restarted {{ $value }} times"
    
    # Pod not ready
    - alert: PodNotReady
      expr: |
        kube_pod_status_phase{namespace="foodfund-k8s", phase!="Running"} == 1
      for: 10m
      labels:
        severity: critical
        component: kubernetes
      annotations:
        summary: "Pod {{ $labels.pod }} not ready"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is in {{ $labels.phase }} state"
